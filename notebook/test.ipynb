{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cba541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Pakistan is **Islamabad**. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "response = llm.invoke(\"What is the capital of Pakistan?\")\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d7b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Text-to-SQL Generator!\n",
      "Error reading CSV file: [Errno 2] No such file or directory: 'exit'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\") \n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGroq(\n",
    "    model_name=\"gemma2-9b-it\",  \n",
    "    temperature=0,  \n",
    ")\n",
    "\n",
    "def get_sql_type(dtype):\n",
    "    \"\"\"\n",
    "    Map pandas dtype to SQL type.\n",
    "    \n",
    "    Args:\n",
    "        dtype: The pandas dtype to map.\n",
    "        \n",
    "    Returns:\n",
    "        str: The corresponding SQL type.\n",
    "    \"\"\"\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return \"INTEGER\"\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return \"REAL\"\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        return \"BOOLEAN\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return \"DATE\"\n",
    "    else:\n",
    "        return \"TEXT\"\n",
    "\n",
    "def generate_schema(df, table_name):\n",
    "    \"\"\"\n",
    "    Generate the schema string for the given DataFrame and table name.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to generate the schema from.\n",
    "        table_name (str): The name of the table.\n",
    "        \n",
    "    Returns:\n",
    "        str: The schema string.\n",
    "    \"\"\"\n",
    "    schema = f\"Table: {table_name}\\n\"\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        sql_type = get_sql_type(dtype)\n",
    "        schema += f\"- {col} ({sql_type})\\n\"\n",
    "    return schema\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to the Text-to-SQL Generator!\")\n",
    "    csv_path = input(\"Please provide the path to your CSV file: \")\n",
    "    \n",
    "    # Read the CSV\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Get table name from file name\n",
    "    table_name = os.path.splitext(os.path.basename(csv_path))[0]\n",
    "    table_name = table_name.replace(\" \", \"_\")  # Simple sanitization\n",
    "    \n",
    "    # Generate schema\n",
    "    schema = generate_schema(df, table_name)\n",
    "    \n",
    "    # Create prompt template\n",
    "    prompt_template = f\"\"\"\n",
    "You are an expert SQL query generator. Given a database with the following schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Please convert the following natural language query into a valid SQL query for this table:\n",
    "\n",
    "User query: {{query}}\n",
    "\n",
    "Return ONLY the SQL query without any explanations or additional text. The query should be complete, executable and follow best practices.\n",
    "\n",
    "SQL Query:\n",
    "\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    \n",
    "    # Create chain\n",
    "    chain = (\n",
    "        {\"query\": RunnablePassthrough()} \n",
    "        | prompt \n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    print(f\"Schema inferred for table '{table_name}':\")\n",
    "    print(schema)\n",
    "    print(\"You can now ask questions about this dataset.\")\n",
    "    \n",
    "    while True:\n",
    "        user_query = input(\"Enter your question (or 'quit' to exit): \")\n",
    "        if user_query.lower() == 'quit':\n",
    "            break\n",
    "        try:\n",
    "            sql_query = chain.invoke(user_query)\n",
    "            print(f\"Generated SQL Query: {sql_query}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating SQL query: {e}\")\n",
    "    \n",
    "    print(\"Thank you for using the Text-to-SQL Generator!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "830b41e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "StreamlitSecretNotFoundError",
     "evalue": "No secrets found. Valid paths for a secrets.toml file or secret directories are: C:\\Users\\fahim\\.streamlit\\secrets.toml, d:\\JMM_Technologies\\Groq\\.streamlit\\secrets.toml",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStreamlitSecretNotFoundError\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Set up Groq API key (assumes it's stored in Streamlit secrets)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGROQ_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecrets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGROQ_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize the LLM\u001b[39;00m\n\u001b[0;32m     13\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatGroq(\n\u001b[0;32m     14\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma2-9b-it\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     16\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\fahim\\miniconda3\\envs\\myenv\\Lib\\site-packages\\streamlit\\runtime\\secrets.py:470\u001b[0m, in \u001b[0;36mSecrets.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the value with the given key. If no such key\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mexists, raise a KeyError.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03mThread-safe.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 470\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[key]\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Mapping):\n\u001b[0;32m    472\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\fahim\\miniconda3\\envs\\myenv\\Lib\\site-packages\\streamlit\\runtime\\secrets.py:372\u001b[0m, in \u001b[0;36mSecrets._parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found_secrets_file:\n\u001b[0;32m    367\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    368\u001b[0m         secret_error_messages_singleton\u001b[38;5;241m.\u001b[39mget_no_secrets_found_message(\n\u001b[0;32m    369\u001b[0m             file_paths\n\u001b[0;32m    370\u001b[0m         )\n\u001b[0;32m    371\u001b[0m     )\n\u001b[1;32m--> 372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StreamlitSecretNotFoundError(error_msg)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m secrets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_set_environment_variable(k, v)\n",
      "\u001b[1;31mStreamlitSecretNotFoundError\u001b[0m: No secrets found. Valid paths for a secrets.toml file or secret directories are: C:\\Users\\fahim\\.streamlit\\secrets.toml, d:\\JMM_Technologies\\Groq\\.streamlit\\secrets.toml"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import os\n",
    "\n",
    "# Set up Groq API key (assumes it's stored in Streamlit secrets)\n",
    "os.environ[\"GROQ_API_KEY\"] = st.secrets[\"GROQ_API_KEY\"]\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGroq(\n",
    "    model_name=\"gemma2-9b-it\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Function to map pandas dtype to SQL type\n",
    "def get_sql_type(dtype):\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return \"INTEGER\"\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return \"REAL\"\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        return \"BOOLEAN\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return \"DATE\"\n",
    "    else:\n",
    "        return \"TEXT\"\n",
    "\n",
    "# Function to generate schema from DataFrame\n",
    "def generate_schema(df, table_name):\n",
    "    schema = f\"Table: {table_name}\\n\"\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        sql_type = get_sql_type(dtype)\n",
    "        schema += f\"- {col} ({sql_type})\\n\"\n",
    "    return schema\n",
    "\n",
    "# Streamlit app\n",
    "def main():\n",
    "    st.title(\"Text-to-SQL Generator\")\n",
    "\n",
    "    # Initialize session state variables\n",
    "    if 'df' not in st.session_state:\n",
    "        st.session_state.df = None\n",
    "    if 'schema' not in st.session_state:\n",
    "        st.session_state.schema = None\n",
    "    if 'table_name' not in st.session_state:\n",
    "        st.session_state.table_name = None\n",
    "\n",
    "    # File uploader for CSV\n",
    "    uploaded_file = st.file_uploader(\"Upload your CSV file\", type=\"csv\")\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(uploaded_file)\n",
    "            st.session_state.df = df\n",
    "\n",
    "            # Derive table name from file name\n",
    "            table_name = uploaded_file.name.split('.')[0].replace(\" \", \"_\")\n",
    "            st.session_state.table_name = table_name\n",
    "\n",
    "            # Generate and store schema\n",
    "            schema = generate_schema(df, table_name)\n",
    "            st.session_state.schema = schema\n",
    "\n",
    "            # Display the schema\n",
    "            st.write(f\"Schema inferred for table '{table_name}':\")\n",
    "            st.code(schema, language=\"markdown\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error reading CSV file: {e}\")\n",
    "\n",
    "    # If schema is available, allow user to ask questions\n",
    "    if st.session_state.schema:\n",
    "        query = st.text_input(\"Enter your question:\", placeholder=\"e.g., What are the top 10 items by sales?\")\n",
    "\n",
    "        if query:\n",
    "            try:\n",
    "                # Create prompt template with the schema\n",
    "                prompt_template = f\"\"\"\n",
    "You are an expert SQL query generator. Given a database with the following schema:\n",
    "\n",
    "{st.session_state.schema}\n",
    "\n",
    "Please convert the following natural language query into a valid SQL query for this table:\n",
    "\n",
    "User query: {{query}}\n",
    "\n",
    "Return ONLY the SQL query without any explanations or additional text. The query should be complete, executable and follow best practices.\n",
    "\n",
    "SQL Query:\n",
    "\"\"\"\n",
    "                prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "                # Create the chain\n",
    "                chain = (\n",
    "                    {\"query\": RunnablePassthrough()}\n",
    "                    | prompt\n",
    "                    | llm\n",
    "                    | StrOutputParser()\n",
    "                )\n",
    "\n",
    "                # Generate SQL query\n",
    "                sql_query = chain.invoke(query)\n",
    "\n",
    "                # Display the generated SQL query\n",
    "                st.write(\"Generated SQL Query:\")\n",
    "                st.code(sql_query, language=\"sql\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error generating SQL query: {e}\")\n",
    "    else:\n",
    "        st.write(\"Please upload a CSV file to start.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4740c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'exit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load the user-provided dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the path to your CSV dataset: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m columns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Define the prompt template with guardrails\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fahim\\miniconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fahim\\miniconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\fahim\\miniconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fahim\\miniconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\fahim\\miniconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'exit'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "# Set your Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")  # Replace with your actual key\n",
    "\n",
    "# Load the user-provided dataset\n",
    "dataset_path = input(\"Enter the path to your CSV dataset: \")\n",
    "df = pd.read_csv(dataset_path)\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "# Define the prompt template with guardrails\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"columns\", \"question\"],\n",
    "    template=\"\"\"You are an SQL expert. Given a table named \"data\" with columns: {columns}, \n",
    "    generate an SQL query for: \"{question}\". \n",
    "    Use only the provided columns. If the question can't be answered, return \"Insufficient data\". \n",
    "    Output only the SQL query, no explanation.\"\"\"\n",
    ")\n",
    "\n",
    "# Set up the Groq model\n",
    "chat_model = ChatGroq(\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model_name=\"gemma2-9b-it\",\n",
    "    temperature=0.0  # For deterministic output\n",
    ")\n",
    "\n",
    "# Create the chain\n",
    "chain = prompt | chat_model\n",
    "\n",
    "question = input(\"Ask a question about the dataset: \")\n",
    "\n",
    "# Generate and display the SQL query\n",
    "response = chain.invoke({\"columns\": \", \".join(columns), \"question\": question})\n",
    "sql_query = response.content.strip()\n",
    "\n",
    "print(\"Generated SQL Query:\")\n",
    "print(sql_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
